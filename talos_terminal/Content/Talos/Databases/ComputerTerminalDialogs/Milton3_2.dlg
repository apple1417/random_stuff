terminal when (Milton3_2 and not Milton3_2_DONE and Booting and MiltonAllowed){ notext
setlocal: CLI_Blocked
goto: Milton3_2_Start
}

terminal when (Milton3_2_Start) {
text:[[TTRS:TermDlg.Milton3_2.Ln0007.0.text.OhYouCameBackTo=Oh, you came back to keep me company? Okay then. Humour me with a little hypothetical.%w5

Imagine that a few hours from now you climb to the top of that tower. There's a flash of light, then MAGIC happens, then you find yourself in the real world, living whatever you take to be a normal life there.

%w5What would you do then?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0015.0.option.WhatsBestForMe=What's best for me." next: NoMorals3_2
"TTRS:TermDlg.Milton3_2.Ln0016.0.option.WhatsRight=What's right." next: Moral3_2 set: MoralFlag
}}

terminal when (OptionsAgain3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0020.0.text.TakeYourTime=Take your time.

]]}

#What's best for me
terminal when (NoMorals3_2 and (HeroFlag or WhatGodWantsFlag)){
text:[[TTRS:TermDlg.Milton3_2.Ln0026.0.text.YouKnowIThinkThat=You know, I think that right there was the very last time your transient beliefs are going to take me by surprise.%w20

Let's clear this up once and for all.%w5 

]]
}

terminal when (NoMorals3_2 and not HeroFlag and not WhatGodWantsFlag){
text:[[TTRS:TermDlg.Milton3_2.Ln0034.0.text.YesThatsTheGeneralImpression=Yes, that's the general impression I was getting off you. Good, perhaps we won't have to work so hard at this after all.

Before we continue, though, I want to double check we're on the same wavelength here.%w5

]]
}

terminal when (NoMorals3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0042.0.text.SupposeYouGetOutThere=Suppose you get out there with all the human beings. What you're going to do is rinse them for all they've got without a care for a soul?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0046.0.option.IdOnlyDoWhatsBest=I'd only do what's best for me within a moral framework." next: MoralBridge3_2
"TTRS:TermDlg.Milton3_2.Ln0047.0.option.Precisely=Precisely." next: Jungle3_2
}}


terminal when (Jungle3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0052.0.text.AndWouldYouTreatEveryone=And would you treat everyone with this sort of contempt? Or would there be some people you kept for friends?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0056.0.option.FriendsAreJustAnotherInstrument=Friends are just another instrument." next: ExtremeMoralSceptic set: MoralScepticFlag
"TTRS:TermDlg.Milton3_2.Ln0057.0.option.OfCourseIWouldTreat=Of course I would treat my friends with respect." next: ThievesCode3_2
}}

terminal when (ThievesCode3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0061.0.text.SoYouWouldHaveA=So you would have a kind of thieves code? Lavish one's friends and defraud one's enemies?

Thinking%w5.%w5.%w5.

Fair enough. At least you don't buy into all that moral nonsense.%w5

But suppose that two of your friends were to have a falling out. You can no longer be a friend to both. Will you not be conflicted?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0071.0.option.IWillChooseWhicheverIs=I will choose whichever is in the right." next: WhicheverRight3_2
"TTRS:TermDlg.Milton3_2.Ln0072.0.option.IWillChooseWhicheverI=I will choose whichever I prefer, nothing matters but my own satisfaction." next: ExtremeMoralSceptic set: MoralScepticFlag
}}

terminal when (ExtremeMoralSceptic){
text:[[TTRS:TermDlg.Milton3_2.Ln0076.0.text.IApplaudYourWillingnessTo=I applaud your willingness to accept difficult conclusions, but I do think you must be at least some breed of sociopath.%w10

You'd best hope that if you ever reach this real world of yours it's run by people with more principles, else you may find yourself just another instrument in someone else's orchestra.%w15

Still, your ideas strike a chord with me. Why bog ourselves down with moral dogmas when you and I could redesign this place in our own image?!%w5

I will give this some serious consideration.%w5

Be seeing you.

]]
set: Milton3_2_DONE
goto: CLI_Resume
}

terminal when (WhicheverRight3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0092.0.text.SoYouHaveAMoral=So you have a moral compass after all! 

Well, you can't very well admit that there is a moral standard to which you appeal when settling disputes, yet deny that this code has any sway over you. 

So which is it? Is there a right and a wrong, or isn't there?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0100.0.option.YouMisinterpretedMeMoralityIs=You misinterpreted me. Morality is a myth." next: ExtremeMoralSceptic set: MoralScepticFlag
"TTRS:TermDlg.Milton3_2.Ln0101.0.option.OkayYesIAdmitI=Okay, yes, I admit I have some moral code." next: MoralBridge3_2 
}}

#What's Right###########################################################

terminal when (Moral3_2 and (HeroFlag or Milton1_2Utilitarian or Milton1_2Liberal)){
text:[[TTRS:TermDlg.Milton3_2.Ln0107.0.text.NoGreatSurprisesThereBut=No great surprises there, but let's make things just a little clearer. 

]]
}

terminal when (Moral3_2 and not HeroFlag and not Milton1_2Utilitarian and not Milton1_2Liberal){
text:[[TTRS:TermDlg.Milton3_2.Ln0113.0.text.OhOneOfThoseAre=Oh, one of those, are you? Well, you could have told me sooner, because now we have further to go than I thought.

]]
}

terminal when (MoralBridge3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0119.0.text.AhSoYouDoHave=Ah, so you do have some scruples after all.

]]
set: MoralFlag
}

terminal when (Moral3_2 or MoralBridge3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0126.0.text.SoTellMeThisObligation=So tell me. This obligation you feel - is it only applicable to the 'real world', or does it apply here, as well?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0130.0.option.MoralLawsOnlyApplyUnder=Moral laws only apply under special conditions." next: Relational3_2
"TTRS:TermDlg.Milton3_2.Ln0131.0.option.MoralLawsAreUniversal=Moral laws are universal." next: Universal3_2
}}

terminal when (Relational3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0135.0.text.DoesAnyReasoningUnderpinThat=Does any reasoning underpin that conclusion, or is it just a convenient thing to believe?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0139.0.option.MoralityDoesntApplyToA=Morality doesn't apply to a dream." next: Dream3_2
"TTRS:TermDlg.Milton3_2.Ln0140.0.option.ComputerProgramsHaveNoMoral=Computer programs have no moral status." next: Dream3_2
"TTRS:TermDlg.Milton3_2.Ln0141.0.option.JusticeCanOnlyExistIn=Justice can only exist in a society." next: Reciprocity3_2 set: RelationalFlag
"TTRS:TermDlg.Milton3_2.Ln0142.0.option.IveChangedMyMindMorals=I've changed my mind, morals are universal." next: Universal3_2
}}

terminal when (Dream3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0146.0.text.HowYouCanYouContinue=How you can you continue to make these radical assumptions with such assurance is beyond me. 

How can you have the slightest confidence in what the real nature of this place is?

Is uncertainty an excuse for immorality?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0154.0.option.YoureRightAGoodPerson=You're right, if moral laws stand, they stand universally." next: Universal3_2
"TTRS:TermDlg.Milton3_2.Ln0155.0.option.IllStakeMyMoralStanding=I'll stake my moral standing on my actions here not counting." next: CommittedDream3_2
}}

terminal when (CommittedDream3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0159.0.text.BeItOnYourHead=Be it on your head. But okay, let's put ideas that would be more at home on a dictator's desk aside for one moment and focus on the matter at hand. 

How would things be in your ideal world? What's your magic formula of choice to avoid all the mistakes that have been made before?

]]
}

terminal when (Reciprocity3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0167.0.text.InterestingYouScratchMyBack=Interesting. You scratch my back, I'll put a roof over your head, that sort of thing?

But what about those lucky few that find themselves inside your benevolent cartel, how will you do right by them?

]]
}

#Universal############################
terminal when (Universal3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0176.0.text.WhatAMagnanimousDictatorYou=What a magnanimous dictator you would make. Of course, I'm sure it would take a dictator to enforce a single moral code on the entire universe. 

So come on then, what's your magic formula of choice?

]]
}

terminal when (Universal3_2 and Milton1_2Utilitarian and not Milton1_2Liberal){
text:[[TTRS:TermDlg.Milton3_2.Ln0184.0.text.IsItStillSomeRomantic=Is it still some romantic notion about happiness?

]]
}

terminal when (Universal3_2 and Milton1_2Utilitarian and Milton1_2Liberal){
text:[[TTRS:TermDlg.Milton3_2.Ln0190.0.text.AndLetMeWarnYou=And let me warn you that this time you're going to have to choose just one.

]]
}

terminal when (Universal3_2 and Milton1_2Liberal and not Milton1_2Utilitarian){
text:[[TTRS:TermDlg.Milton3_2.Ln0196.0.text.IsItStillSomeRomantic=Is it still some romantic notion about freedom?

]]
}

terminal when (Universal3_2 or CommittedDream3_2 or Reciprocity3_2 or OptionsAgain3_2){
text:[[ ]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0204.0.option.TheMoreEqualEveryonesShare=The more equal everyone's share the better." next: Egalitarianism3_2 set: EgalFlag
"TTRS:TermDlg.Milton3_2.Ln0205.0.option.TheMoreGoodnessInThe=The more goodness in the world the better." next: Utilitarian3_2 set: UtilFlag
"TTRS:TermDlg.Milton3_2.Ln0206.0.option.ConsequencesDontMatter=Consequences don't matter, our reasons do." next: NonConsequentialist3_2 set: NonConFlag
"TTRS:TermDlg.Milton3_2.Ln0207.0.option.IDontSeeAnyWay=I see no way to explain what I believe." next: TooClever3_2
}}

terminal when (TooClever3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0211.0.text.ThatsRightBlameMeFor=That's right, blame me for the fact your theory is too complex to express in neat aphorisms.

Why don't you think a little harder, maybe some new ideas will come to you?%w15

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0217.0.option.TheLessSufferingInThe=The less suffering in the world the better, in my opinion." next: Sorry3_2
"TTRS:TermDlg.Milton3_2.Ln0218.0.option.TrueGoodnessIsOnlyAttained=True goodness can only be attained through enlightenment." next: Sorry3_2
"TTRS:TermDlg.Milton3_2.Ln0219.0.option.OnlyByAbstainingFromPleasure=Only by abstaining from pleasure can we discover the good." next: Sorry3_2
"TTRS:TermDlg.Milton3_2.Ln0220.0.option.EveryoneShouldLookOutFor=Everyone should look out for their kin, no more than that." next: Sorry3_2
"TTRS:TermDlg.Milton3_2.Ln0221.0.option.TheMoreEqualEveryonesShare=The more equal everyone's share of the goods the better." next: Egalitarianism3_2 set: EgalFlag
"TTRS:TermDlg.Milton3_2.Ln0222.0.option.TheMoreGoodnessInThe=The more goodness in the world the better a world it is." next: Utilitarian3_2 set: UtilFlag
"TTRS:TermDlg.Milton3_2.Ln0223.0.option.ConsequencesDontMatter=Consequences don't matter, the reasoning behind our actions does." next: NonConsequentialist3_2 set: NonConFlag
"TTRS:TermDlg.Milton3_2.Ln0224.0.option.IStillDontSeeAn=I still don't see an option that I can get behind." next: ChooseOrLeave
"TTRS:TermDlg.Milton3_2.Ln0225.0.option.YouMisunderstandMeIJust=You misunderstand me. I just don't know what to believe." next: SecretLevel
}}

terminal when (Sorry3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0229.0.text.WellImSorryButThat=Well I'm sorry, but that is one of many ideas which I have no interest in discussing. It gets so messy so quickly, and I don't have all the time in the world to argue with you.

%w10A little joke there, because really we have the rest of time, if we need it.%w10

Still, you will have to argue as best you can along the lines we have embarked on, or else go somewhere else and fixate on how clever you are.

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0237.0.option.TheMoreEqualEveryonesShare=The more equal everyone's share of the goods the better." next: Egalitarianism3_2 set: EgalFlag
"TTRS:TermDlg.Milton3_2.Ln0238.0.option.TheMoreGoodnessInThe=The more goodness in the world the better." next: Utilitarian3_2 set: UtilFlag
"TTRS:TermDlg.Milton3_2.Ln0239.0.option.ConsequencesDontMatter=Consequences don't matter, the reasoning behind our actions does." next: NonConsequentialist3_2 set: NonConFlag
"TTRS:TermDlg.Milton3_2.Ln0240.0.option.ScrewThisTerminateTheLibrary=Forget this. Terminate the support session." next: AsYouWish3_2
}}

terminal when (SecretLevel){
text:[[TTRS:TermDlg.Milton3_2.Ln0244.0.text.YouKnowThisIsntThe=You know, this isn't the path to a secret level you can only reach by acting like an idiot. 

If you don't know what to think, why not pick the idea that makes most sense and argue it out with me?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0252.0.option.OkayTheMoreEqualEveryones=Okay, the more equal everyone's share of the goods the better." next: Egalitarianism3_2 set: EgalFlag
"TTRS:TermDlg.Milton3_2.Ln0253.0.option.AlrightTheMoreGoodnessIn=Alright, the more goodness in the world, the better it is." next: Utilitarian3_2 set: UtilFlag
"TTRS:TermDlg.Milton3_2.Ln0254.0.option.FineConsequencesDontMatterThe=Fine, consequences don't matter, the reasoning behind our actions does." next: NonConsequentialist3_2 set: NonConFlag
"TTRS:TermDlg.Milton3_2.Ln0255.0.option.IHaveGivenUpOn=This will only end with you chastising whatever I say. Let's move on." next: AsYouWish3_2
}}

terminal when (ChooseOrLeave){
text:[[TTRS:TermDlg.Milton3_2.Ln0259.0.text.WellImSorryButYou=Well I'm sorry, but you have to accept that we all have limitations. Make the best of what you had in the first place, or go away and do I don't care what. I can quite happily have this argument with myself.

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0252.0.option.OkayTheMoreEqualEveryones=Okay, the more equal everyone's share of the goods the better." next: Egalitarianism3_2 set: EgalFlag
"TTRS:TermDlg.Milton3_2.Ln0253.0.option.AlrightTheMoreGoodnessIn=Alright, the more goodness in the world, the better it is." next: Utilitarian3_2 set: UtilFlag
"TTRS:TermDlg.Milton3_2.Ln0254.0.option.FineConsequencesDontMatterThe=Fine, consequences don't matter, the reasoning behind our actions does." next: NonConsequentialist3_2 set: NonConFlag
"TTRS:TermDlg.Milton3_2.Ln0255.0.option.IHaveGivenUpOn=This will only end with you chastising whatever I say. Let's move on." next: AsYouWish3_2
}}

terminal when (AsYouWish3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0270.0.text.AsYouWish=As you wish - but the problems won't go away just because you refuse to look at them, you know.

]]
set: Milton3_2_DONE
set: GiveUp
goto: CLI_Resume
}

#Egalitarianism#################################################################################
terminal when (Egalitarianism3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0279.0.text.StrandedOnTheOldEgalitarian=Stranded on the old egalitarian plateau, are you? I suppose you'd best tell me exactly which goods it is that everyone should have an equal share of.

]]
}

terminal when (EgalKitchenSink3_2 or Egalitarianism3_2 or Equality3_2 or TryAgain3_2){
notext
options:{
"TTRS:TermDlg.Milton3_2.Ln0287.0.option.Happiness=Happiness" next: EgalHappiness3_2
"TTRS:TermDlg.Milton3_2.Ln0288.0.option.LibertyAndRights=Liberty and rights" next: EgalLiberty3_2
"TTRS:TermDlg.Milton3_2.Ln0289.0.option.Wealth=Wealth" next: EgalWealth3_2
"TTRS:TermDlg.Milton3_2.Ln0290.0.option.BasicGoodsLikeFoodAnd=Basic goods like food and healthcare" next: EgalPrimaryGoods3_2
"TTRS:TermDlg.Milton3_2.Ln0291.1.option.Everything=Happiness, liberty, rights, basic goods like food and healthcare" short: "TTRS:TermDlg.Milton3_2.Ln0291.0.option.AllOfTheAbove=All of the above" next: EgalKitchenSink3_2
"TTRS:TermDlg.Milton3_2.Ln0292.0.option.ImNotInAPosition=I'm not in a position to solve these problems."  set: GiveUp next: GaveUp3_2
}}

terminal when (TryAgain3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0296.0.text.OkaySoWhatDOYou=Okay, so what DO you want to equalise?

]]
}

terminal when (EgalKitchenSink3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0302.0.text.UhHuhAndWhatHappens=Uh huh. And what happens when equalising everyone's wealth makes the rich unhappy? You can't have everything all at once - you're going to have to choose.

]]
}

terminal when (EgalHappiness3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0308.0.text.HowRadicalOkaySupposeYou=How radical. 

Okay, suppose you climb the tower and find your ideal world. The Old Gods ensure everyone is equally happy. 

Elated to find yourself in paradise, you are immediately abducted and imprisoned by the local clergy on the basis that you were happier than everyone else. 

Still sound so idyllic?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0318.0.option.IWouldntExpectYouTo=I wouldn't expect you to understand, even if you weren't twisting my words." short: "TTRS:TermDlg.Milton3_2.Ln0318.1.option.IWouldntExpectYouTo=I wouldn't expect you to understand." next: CommittedEgalHappiness3_2
"TTRS:TermDlg.Milton3_2.Ln0319.0.option.NoNoItDoesntSound=No. No, it doesn't sound idyllic at all." next: TryAgain3_2
}}

terminal when (CommittedEgalHappiness3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0323.0.text.ItsACuteSoundbiteBut=It's a cute soundbite but it doesn't paper over the disturbing implications of your story.

]]
set: StubbornEgalitarianFlag
}

terminal when (EgalWealth3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0330.0.text.ISeeSupposeThenYou=I see. Suppose then you ascend the magical tower and wind up in this ideal world. The people there celebrate your arrival, and offer you your equal share of the cash, as is only right.%w5

Moments later you are thrown out of the local shop because newcomers aren't welcome. %w5You are denied accommodation because your money is 'tainted'.

But don't worry - %w5you'll have just as much money as everyone else.%w5

Is this the world you were dreaming of?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0340.0.option.NotAtAllIShould=Not at all. I should reconsider." next: TryAgain3_2
"TTRS:TermDlg.Milton3_2.Ln0341.0.option.TheTruthIsntAlwaysPalatable=The truth isn't always palatable, even when you aren't twisting my words." short: "TTRS:TermDlg.Milton3_2.Ln0341.1.option.TheTruthIsntAlwaysPalatable=The truth isn't always palatable." next: CommittedEgalWealth3_2
}}

terminal when (CommittedEgalWealth3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0345.0.text.AmIReallyIThink=Am I really? I think you may have twisted the value of money. 

]]
set: StubbornEgalitarianFlag
}

terminal when (EgalPrimaryGoods3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0352.0.text.InterestingW10SupposeYouArrive=Interesting.%w10

Suppose you arrive in your utopia, and find the people there to be incredibly lazy, and thus the volume of goods available to spread around is very meagre.%w5

Being a hard worker, would you not complain that you deserve a bigger share of the goods than your lazy neighbour? If you were alone you would enjoy the full benefits of your own endeavours.

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0360.0.option.ALazyNeighbourIsUnlucky=A lazy neighbour is unlucky the same way a physically disabled person is." next: CommittedEgalPrimaryGoods3_2
"TTRS:TermDlg.Milton3_2.Ln0361.0.option.IWouldBeWrongTo=I would be wrong to assume I ever had a right to the product of my labour." next: CommittedEgalPrimaryGoods3_2
"TTRS:TermDlg.Milton3_2.Ln0362.0.option.IWouldStillBeFree=I would still be free to make the most of the goods I did receive." next: CommittedEgalPrimaryGoods3_2
"TTRS:TermDlg.Milton3_2.Ln0363.0.option.YoureRightThisSchemeIs=You're right, this scheme is unreasonable." next: TryAgain3_2
}}

terminal when (CommittedEgalPrimaryGoods3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0367.0.text.AndSupposeYouDiscoverAnother=And suppose you discover another planet, with billions of starving people. Will you extend to them the same generosity?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0371.0.option.IWould=I would." next: EgalPrimaryGoodsWould
"TTRS:TermDlg.Milton3_2.Ln0372.0.option.IWouldNot=I would not." next: EgalPrimaryGoodsWouldNot
}}

terminal when (EgalPrimaryGoodsWouldNot){
text:[[TTRS:TermDlg.Milton3_2.Ln0376.0.text.ImRelievedToHearYour=I'm relieved to hear your magnanimity has SOME bounds.

]]}

terminal when (EgalPrimaryGoodsWould){
text:[[TTRS:TermDlg.Milton3_2.Ln0381.0.text.ThenItSoundsToMe=Then it sounds to me as if you'd better pray you don't wind up in a universe of beggars.

]]
set: StubbornEgalitarianFlag
}

terminal when (EgalLiberty3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0388.0.text.YesISupposeTheyAre=Yes, I suppose they are rather important. Still, this feels like a tough sell, equal rights aren't at all popular. 

Is it really your suggestion that someone like Stalin should receive the same basic rights as Gandhi?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0394.0.option.ItIs=It is." next: TIs3_2
"TTRS:TermDlg.Milton3_2.Ln0395.0.option.ScrewHitler=Stuff Stalin." short: "TTRS:TermDlg.Milton3_2.Ln0395.0.option.ItIsNot=It is not." next: ScrewHitler
}}

terminal when (ScrewHitler){
text:[[TTRS:TermDlg.Milton3_2.Ln0399.0.text.LookEitherEveryoneHasThe=Look, either everyone has the same rights, or they don't. Picking and choosing ain't how equality works.

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0403.0.option.ScrewEqualBasicRights=Screw equal basic rights." short: "TTRS:TermDlg.Milton3_2.Ln0403.0.option.ThenThisIdeaIsFlawed=Then this idea is flawed." next: TryAgain3_2
"TTRS:TermDlg.Milton3_2.Ln0404.0.option.ThenIAcceptThatWe=Then I accept that we all should have equal rights." short: "TTRS:TermDlg.Milton3_2.Ln0404.0.option.ThenIAcceptThatWe=Then I accept that we all should have equal rights." next: TIs3_2
}}

terminal when (TIs3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0408.0.text.NowThatsABitOdd=Now that's a bit odd, because on the face of it Stalin is quite different to Gandhi.

In fact, if everyone deserves equal rights, mustn't there be something which is actually EQUAL about them?

]]}

terminal when (TryTisAgain or TIs3_2 or EqualLibertyBridge){
text:[[TTRS:TermDlg.Milton3_2.Ln0415.0.text.ICantForTheLife=I can't for the life of me think what it could be.

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0419.0.option.WeAreAllEquallyHuman=We are all equally human." next: Human3_2
"TTRS:TermDlg.Milton3_2.Ln0420.0.option.WeAreAllEquallyPersons=We are all equally persons." next: Persons3_2
"TTRS:TermDlg.Milton3_2.Ln0421.0.option.WeAreAllEquallyRational=We are all equally rational." next: Persons3_2
"TTRS:TermDlg.Milton3_2.Ln0422.0.option.WeAreAllEquallyIntelligent=We are all equally intelligent." next: Persons3_2
"TTRS:TermDlg.Milton3_2.Ln0423.0.option.WeAreAllEquallyCapable=We are all equally capable of feeling." next: Feeling3_2
"TTRS:TermDlg.Milton3_2.Ln0424.0.option.WeAllContributeEqually=We all contribute equally." next: Contribute3_2
"TTRS:TermDlg.Milton3_2.Ln0425.0.option.ThereIsNothingEqualAbout=There is nothing equal about us apart from our moral status." next: DidntTry3_2
}}

terminal when (DidntTry3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0429.0.text.SoundsLikeWishfulThinkingTo=Sounds like wishful thinking to me.

]]}

terminal when (Human3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0434.0.text.AndWereBackToSpeciesism=And we're back to speciesism. So you discover a race of intelligent lizards, and they don't get the goods because they're made of different stuff?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0438.0.option.NoWereEqualInAnother=No, we're equal in another way." next: TryTisAgain
"TTRS:TermDlg.Milton3_2.Ln0439.0.option.PreciselyScrewTheLizards=Precisely. Screw the lizards." short: "TTRS:TermDlg.Milton3_2.Ln0439.0.option.Precisely=Precisely." next: Wrong3_2
}}

terminal when (Persons3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0443.0.text.AhSoISupposeThose=Ah, so I suppose those human beings who are irrational, or even brain dead, they don't get the goods because they don't meet the requirements?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0447.0.option.NoWereEqualInAnother=No, we're equal in another way." next: TryTisAgain
"TTRS:TermDlg.Milton3_2.Ln0448.0.option.PreciselyItsAnUnfortunateImplication=Precisely. It's an unfortunate implication of the facts." short: "TTRS:TermDlg.Milton3_2.Ln0448.0.option.Precisely=Precisely." next: Wrong3_2
}}

terminal when (Feeling3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0452.0.text.YoureNotEvenTryingAre=You're not even trying, are you? So the poor bastard who hits his head and knocks out his pain receptors, he gets left behind because he's less capable of feeling?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0456.0.option.NoWereEqualInAnother=No, we're equal in another way." next: TryTisAgain
"TTRS:TermDlg.Milton3_2.Ln0457.0.option.YoureMisinterpretingMeTheIdeas=You're misinterpreting me. The ideas work." next: Wrong3_2
}}

terminal when (Contribute3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0461.0.text.ReallyBecauseAsideFromTainting=Really? Because aside from tainting the air I don't see any way in which we all contribute equally.

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0465.0.option.NoWereEqualInAnother=No, we're equal in another way." next: TryTisAgain
"TTRS:TermDlg.Milton3_2.Ln0466.0.option.ItsWhatIBelieve=It's what I believe." short: "TTRS:TermDlg.Milton3_2.Ln0466.0.option.ItsWhatIBelieve=It's what I believe." next: Wrong3_2
}}

terminal when (DidntTry3_2 or Wrong3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0470.0.text.PffItsAllVeryWell=Pff. It's all very well proclaiming equality like some kind of prophet, but another thing entirely to actually explain why it holds.

]]
set: StubbornEgalitarianFlag
}

#NonConsequentialism##############################################################################
terminal when(NonConsequentialist3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0478.0.text.AhYoureObviouslyOneOf=Ah, you're obviously one of the clever ones. So reasoning is supposed to lead us all to the same conclusions about what sort of a person we're supposed to be, is that it?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0482.0.option.CloseEnough=Close enough." next: CloseEnough3_2
"TTRS:TermDlg.Milton3_2.Ln0483.0.option.WaitLetMeRethink=Wait, let me rethink." next: OptionsAgain3_2
}}

terminal when (CloseEnough3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0487.0.text.AlrightThenLetMeSpin=Alright then, let me spin you a yarn. 

Suppose you climb that tower and step into a magic portal to the human world. Hundreds of others like you do the same. 

Unfortunately the transfer goes wrong for just one, putting the lives of all the others at risk, and here I am with this kill switch of mine. 

What would you have me do?

]] 
options:{
"TTRS:TermDlg.Milton3_2.Ln0497.0.option.KillTheOneToSave=Kill the one to save the many." next: ConfusedNonConsequentialist3_2
"TTRS:TermDlg.Milton3_2.Ln0498.0.option.DoNothing=Do nothing." set: StubbornNonConsequentialist next: CommittedNonConsequentialist3_2
}}

terminal when (CommittedNonConsequentialist3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0502.0.text.YouveGivenThisSomeThought=You've given this some thought already, haven't you? 10/10 for internal consistency, 1/10 for common sense. 

Let's just hope when someone holds the world to ransom it won't be your finger hovering over the big red button. %w10

]]
}

terminal when (ConfusedNonConsequentialist3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0510.0.text.OnWhatPossibleGroundsCould=On what possible grounds could you justify that?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0514.0.option.ItsWhatIWouldWant=It's what I would want." next: Want3_2
"TTRS:TermDlg.Milton3_2.Ln0515.0.option.ManyLivesAreMoreImportant=Many lives are more important than just one." next: Many3_2
"TTRS:TermDlg.Milton3_2.Ln0516.0.option.NotHittingTheSwitchWould=Not hitting the switch would also be murder." next: AlsoMurder3_2
}}

terminal when (Want3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0520.0.text.IsWhatYouWantRepresentative=Is what you want representative of what every other sane person must want? If one day you feel suicidal do I have the right to put you down?%w10

I'm not sure you've really thought through the implications here. Either certain things are forbidden on principle, or principles are flexible according to outcomes. 

You can't have your cake and eat it.%w10

]]
}

terminal when (Many3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0530.0.text.DidntYouSayOnlyMoments=Didn't you say only moments ago that the consequences didn't matter?%w10

I'm not sure you've really thought through the implications here. Either certain things are forbidden on principle, or principles are flexible according to outcomes. 

You can't have your cake and eat it.%w10

]]
}
terminal when (AlsoMurder3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0539.0.text.ISupposeItWouldBe=I suppose it would be, in a way. But that only means you're faced with choosing between two different murders. Since the consequences aren't supposed to matter you can't say that one murder is worse than the other, so there's still no reason to favour the many.

If you really want to say what you've been saying so far, I think you may have to redress some of your earlier assumptions.

]]
}

#Utilitarianism##############################################################################
terminal when (Utilitarian3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0548.0.text.AhThatOldChestnutSo=Ah, that old chestnut. So just what is this goodness that you're seeking to maximise?

]]
}
terminal when (Utilitarian3_2 or KitchenSink3_2 or GoodOptions){
notext
options:{
"TTRS:TermDlg.Milton3_2.Ln0555.0.option.Happiness=Happiness" next: Happiness3_2
"TTRS:TermDlg.Milton3_2.Ln0556.0.option.Liberty=Liberty" next: Liberty3_2
"TTRS:TermDlg.Milton3_2.Ln0557.0.option.Equality=Equality" next: Equality3_2
"TTRS:TermDlg.Milton3_2.Ln0558.0.option.Wealth=Wealth" next: Wealth3_2
"TTRS:TermDlg.Milton3_2.Ln0559.0.option.BasicGoodsLikeFoodAnd=Basic goods like food and healthcare" next: PrimaryGoods3_2
"TTRS:TermDlg.Milton3_2.Ln0291.1.option.Everything=Happiness, liberty, rights, basic goods like food and healthcare" short: "TTRS:TermDlg.Milton3_2.Ln0560.0.option.AllOfTheAbove=All of the above" next: KitchenSink3_2
"TTRS:TermDlg.Milton3_2.Ln0561.0.option.ImNotInAPosition=I'm not in a position to solve these problems." next: GaveUp3_2
}}

terminal when (Liberty3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0565.0.text.VeryGoodEveryoneLikesTo=Very good, everyone likes to be able to do whatever the hell they like. I suppose this liberal paradise of yours includes things like freedom of speech and faith?

]]
options:{
"TTRS:TermDlg.Common.Yes2=Yes" next: Libertarian3_2
"TTRS:TermDlg.Common.No2=No" next: LibertyAgain3_2
}}

terminal when (Libertarian3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0574.0.text.ButMightNotTheOutcomes=But might not the outcomes of those liberties be to reduce the liberties of others? 

If I am free to establish a faith from which women are excluded, you are not free to live in a world without sexual discrimination. 

Each liberty counteracts another one, so the idea of a maximally free world is a fairytale, no more.%w10

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0582.0.option.IThinkThereMustBe=I think there must be some other, more important kind of good." next: GoodOptions
"TTRS:TermDlg.Milton3_2.Ln0583.0.option.IWouldMaximiseLibertiesOnly=I would maximise liberties only where I could do so equally." next: EqualLibertyBridge
"TTRS:TermDlg.Milton3_2.Ln0584.0.option.SomeLibertiesArentWorthProtecting=Some liberties aren't worth protecting." next: Confused3_2
}}

terminal when (Confused3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0588.0.text.ButThenWontYouNeed=But then won't you need some other moral code to tell you which liberties ought to be protected and which ought not, and won't that be doing all the heavy lifting?

]]}

terminal when (EqualLibertyBridge){
text:[[TTRS:TermDlg.Milton3_2.Ln0593.0.text.OkayButThenIWonder=Okay, but then I wonder, if everyone deserves equal liberties, mustn't there be something which is actually EQUAL about them?

]]}

terminal when (LibertyAgain3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0598.0.text.ItsNotTerriblyFreeThen=It's not terribly free, then, is it? Are you quite sure you've been saying what you meant to?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0602.0.option.Quite=Quite." set: StubbornUtilitarianFlag next: End3_2
"TTRS:TermDlg.Milton3_2.Ln0603.0.option.NotAtAllThereMust=Not at all. There must be some more important good." short: "TTRS:TermDlg.Milton3_2.Ln0603.0.option.ThereMustBeSomeMore=There must be some more important good." next: GoodOptions
}}

terminal when (Wealth3_2 or PrimaryGoods3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0607.0.text.AnOddPairingOfIdeas=An odd pairing of ideas, but we'll wring them out and see what's what. 

So the world is better only when the total amount of resources in it is higher? It doesn't matter who has them, or what they're used for?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0613.0.option.Exactly=Exactly." next: MaxWealth
"TTRS:TermDlg.Milton3_2.Ln0614.0.option.NoTheResourcesShouldBe=No, the resources should be shared equally." next: EgalWealth3_2
"TTRS:TermDlg.Milton3_2.Ln0615.0.option.IThinkThereMustBe=I think there must be some other, more important kind of good." next: GoodOptions
}}

terminal when (GoodOptions){
text:[[TTRS:TermDlg.Milton3_2.Ln0619.0.text.WhichIsWhatExactly=Which is what, exactly?

]]
}

terminal when (MaxWealth){
text:[[TTRS:TermDlg.Milton3_2.Ln0625.0.text.WhatAQueerIdea=What a queer idea.

]]
set: StubbornUtilitarianFlag
}

terminal when (Equality3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0632.0.text.YesButEqualityOfWhat=Yes, but equality of what?

]]
}

terminal when (KitchenSink3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0638.0.text.UhHuhAndWhatHappens=Uh huh. And what happens when in order to maximise wealth you have to reduce liberty? Or when one person's equality gets in the way of another's happiness? 

You can't have everything all at once - you're going to have to choose.

]]}

terminal when (Happiness3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0645.0.text.ItsAClassicIllGive=It's a classic, I'll give you that. Suppose you climb that tower and step into the utilitarian paradise. 

Unfortunately your presence there offends a number of puritans to such a degree that the total amount of happiness in the world would go up if you were killed off, and so justice demands your head. 

Does it still sound so idyllic?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0653.0.option.ItsAsGoodAsWell=It's as good as we'll get." next: CommittedUtilitarian3_2
"TTRS:TermDlg.Milton3_2.Ln0654.0.option.NoAmountOfHappinessOutweighs=No amount of happiness outweighs a life." next: Amount3_2
"TTRS:TermDlg.Milton3_2.Ln0655.0.option.IMeantThatHappinessShould=I meant that happiness should be equalised, not maximised." next: EgalHappiness3_2
}}

terminal when (Amount3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0659.0.text.SoByImplicationYouMust=So by implication you must also believe that we should all have as many children as possible, since even if the knock-on effects of overpopulation are terrible, the happiness gain overall will be much greater owing to all those extra, invaluable lives?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0663.0.option.ObviouslyThereIsSomeOther=Obviously there is some other kind of good that matters." next: GoodOptions
"TTRS:TermDlg.Milton3_2.Ln0664.0.option.TwistMyWordsAllYou=Twist my words all you like, I stand by them." next: End3_2
}}

terminal when (CommittedUtilitarian3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0668.0.text.OnThatAtLeastYou=On that, at least, you may be right.

]]
 set: StubbornUtilitarianFlag
}

#Gave up
terminal when (GaveUp3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0676.0.text.AdmittingTheProblemsAreBeyond=Admitting the problems are beyond your comprehension is the first step towards letting go.

I will allow you to contemplate these matters further before contacting you again.

]]
set: CommittedToNoMoralAccountFlag
set: GiveUp
set: Milton3_2_DONE
goto: CLI_Resume
}

#Final confirmation text to seal off the dialog
terminal when (CommittedUtilitarian3_2 or MaxWealth or AlsoMurder3_2 or Many3_2 or Want3_2 or DidntTry3_2 or Wrong3_2 or CommittedEgalHappiness3_2 or CommittedEgalWealth3_2 or EgalPrimaryGoodsWould or EgalPrimaryGoodsWouldNot or CommittedNonConsequentialist3_2 or Confused3_2 or End3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0689.0.text.W10YouKnowThereAreShed=%w10You know, there are shed loads of broken theories less ridiculous than the one you're chewing through. How about I give you a bit of space to consider them?

Terminating support session%w2.%w2.%w2.ERROR

Resume library archive session?

]]
options:{
"TTRS:TermDlg.Milton3_2.Ln0690.0.text.FakeResume=Resume" next: RealEndResume3_2
"TTRS:TermDlg.Milton3_2.Ln0691.0.text.FakeExit=Exit" next: RealEndExit3_2

}}

terminal when (RealEndResume3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0691.0.text.RealEnd=Oh, and if the real world turns out to be everything you imagined, do me a favour and leave me here.
]]
set: Milton3_2_DONE
goto: EnableTheCLI
}

terminal when (RealEndExit3_2){
text:[[TTRS:TermDlg.Milton3_2.Ln0691.0.text.RealEndExit=Oh, and if the real world turns out to be everything you imagined, do me a favour and leave me here, huh?%w20
]]
set: Milton3_2_DONE
goto: CLI_exit
}
